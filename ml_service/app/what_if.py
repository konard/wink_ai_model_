import re
from typing import Dict, Any, List, Tuple, cast
from loguru import logger
from sentence_transformers import SentenceTransformer, util
import numpy as np

from .repair_pipeline import (
    parse_script_to_scenes,
    extract_scene_features,
    normalize_and_contextualize_scores,
    map_scores_to_rating,
)


class WhatIfAnalyzer:
    def __init__(self):
        logger.info("Initializing What-If Analyzer")
        self.embedder = SentenceTransformer("all-MiniLM-L6-v2")

        self.modification_patterns = {
            "remove_scenes": [
                r"—É–±—Ä–∞—Ç—å —Å—Ü–µ–Ω[—É—ã]?\s+(\d+)(?:\s*[-‚Äì‚Äî]\s*(\d+))?",
                r"—É–¥–∞–ª–∏—Ç—å —Å—Ü–µ–Ω[—É—ã]?\s+(\d+)(?:\s*[-‚Äì‚Äî]\s*(\d+))?",
                r"–±–µ–∑ —Å—Ü–µ–Ω[—ã–∏]?\s+(\d+)(?:\s*[-‚Äì‚Äî]\s*(\d+))?",
                r"remove scene[s]?\s+(\d+)(?:\s*[-‚Äì‚Äî]\s*(\d+))?",
                r"delete scene[s]?\s+(\d+)(?:\s*[-‚Äì‚Äî]\s*(\d+))?",
            ],
            "reduce_violence": [
                r"–∑–∞–º–µ–Ω–∏—Ç—å\s+.*?(–¥—Ä–∞–∫[—É–∏]|–Ω–∞—Å–∏–ª–∏–µ|–±–æ–π|—É–±–∏–π—Å—Ç–≤[–æ–∞]).*?–Ω–∞\s+(.*?)(?:\.|$|,)",
                r"—Å–º—è–≥—á–∏—Ç—å\s+.*?(–¥—Ä–∞–∫[—É–∏]|–Ω–∞—Å–∏–ª–∏–µ|–±–æ–π)",
                r"—É–±—Ä–∞—Ç—å\s+.*?(–¥—Ä–∞–∫[—É–∏]|–Ω–∞—Å–∏–ª–∏–µ|–±–æ–π|—É–±–∏–π—Å—Ç–≤[–æ–∞]|–æ—Ä—É–∂–∏)",
                r"replace\s+.*?(fight|violence|battle|killing|weapon).*?with\s+(.*?)(?:\.|$|,)",
                r"reduce\s+.*?(fight|violence|battle|weapon)",
                r"remove\s+.*?(fight|violence|battle|killing|weapon)",
                r"–±–µ–∑\s+.*?(–¥—Ä–∞–∫|–Ω–∞—Å–∏–ª|–±–æ[–µ—è]|–æ—Ä—É–∂–∏)",
                r"no\s+.*?(fight|violence|weapon)",
            ],
            "reduce_profanity": [
                r"—É–±—Ä–∞—Ç—å\s+–º–∞—Ç",
                r"—É–¥–∞–ª–∏—Ç—å\s+–º–∞—Ç",
                r"–±–µ–∑\s+–º–∞—Ç[–∞–∏]",
                r"—É–±—Ä–∞—Ç—å\s+.*?(?:–º–∞—Ç|–Ω–µ–Ω–æ—Ä–º–∞—Ç–∏–≤–Ω|–Ω–µ—Ü–µ–Ω–∑—É—Ä–Ω)",
                r"—É\s+–ø–µ—Ä—Å–æ–Ω–∞–∂[–∞–µ]\s+(\w+)",
                r"remove\s+profanity",
                r"remove\s+swearing",
                r"no\s+profanity",
                r"remove\s+all\s+profanity",
            ],
            "reduce_gore": [
                r"—É–±—Ä–∞—Ç—å\s+–∫—Ä–æ–≤[—å–∏]",
                r"–±–µ–∑\s+–∫—Ä–æ–≤[–∏–∏]",
                r"—Å–º—è–≥—á–∏—Ç—å\s+.*?–∫—Ä–æ–≤[—å–∏]",
                r"—É–±—Ä–∞—Ç—å\s+.*?—É–≤–µ—á–∏",
                r"–±–µ–∑\s+.*?(?:–∫—Ä–æ–≤–∏|—É–≤–µ—á–∏)",
                r"remove\s+blood",
                r"remove\s+gore",
                r"reduce\s+gore",
                r"no\s+blood",
            ],
            "reduce_sexual": [
                r"—É–±—Ä–∞—Ç—å\s+.*?(—Å–µ–∫—Å|–∏–Ω—Ç–∏–º|–Ω–∞–≥)",
                r"–±–µ–∑\s+.*?(—Å–µ–∫—Å|–∏–Ω—Ç–∏–º|–Ω–∞–≥)",
                r"—Å–º—è–≥—á–∏—Ç—å\s+.*?(—Å–µ–∫—Å|–∏–Ω—Ç–∏–º)",
                r"remove\s+.*?(sex|nudity|intimate|sexual)",
                r"reduce\s+.*?(sex|sexual)",
                r"no\s+.*?(sex|sexual)",
            ],
            "reduce_drugs": [
                r"—É–±—Ä–∞—Ç—å\s+.*?(?:–Ω–∞—Ä–∫–æ—Ç–∏–∫|–∞–ª–∫–æ–≥–æ–ª—å|–∫—É—Ä–µ–Ω)",
                r"–±–µ–∑\s+.*?(?:–Ω–∞—Ä–∫–æ—Ç–∏–∫|–∞–ª–∫–æ–≥–æ–ª—å|–∫—É—Ä–µ–Ω)",
                r"remove\s+.*?(?:drug|alcohol|smoking)",
                r"no\s+.*?(?:drug|alcohol|smoking)",
            ],
        }

        self.context_examples = {
            "replace_violence_verbal": [
                "verbal confrontation without physical violence",
                "heated argument instead of fight",
                "—Å–ª–æ–≤–µ—Å–Ω—ã–π –∫–æ–Ω—Ñ–ª–∏–∫—Ç –≤–º–µ—Å—Ç–æ –¥—Ä–∞–∫–∏",
                "–Ω–∞–ø—Ä—è–∂–µ–Ω–Ω—ã–π —Å–ø–æ—Ä –≤–º–µ—Å—Ç–æ –±–æ—è",
            ],
            "replace_violence_mild": [
                "stylized action without graphic violence",
                "cartoon-style action sequence",
                "—Å—Ç–∏–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —ç–∫—à–Ω –±–µ–∑ –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–≥–æ –Ω–∞—Å–∏–ª–∏—è",
                "–º—É–ª—å—Ç—è—à–Ω—ã–π —Å—Ç–∏–ª—å –±–æ–µ–≤—ã—Ö —Å—Ü–µ–Ω",
            ],
        }

    def analyze_modification_request(self, request: str) -> Dict[str, Any]:
        """Parse user's what-if request and extract modification intent."""
        request_lower = request.lower()
        modifications = {
            "remove_scenes": [],
            "reduce_violence": False,
            "reduce_profanity": False,
            "reduce_gore": False,
            "reduce_sexual": False,
            "reduce_drugs": False,
            "violence_replacement": None,
        }

        for pattern_type, patterns in self.modification_patterns.items():
            for pattern in patterns:
                match = re.search(pattern, request_lower, re.I | re.U)
                if match:
                    if pattern_type == "remove_scenes":
                        start_scene = int(match.group(1))
                        end_scene = (
                            int(match.group(2)) if match.group(2) else start_scene
                        )
                        scene_list = cast(List[int], modifications["remove_scenes"])
                        scene_list.extend(range(start_scene, end_scene + 1))
                    elif pattern_type == "reduce_violence":
                        modifications["reduce_violence"] = True
                        if match.lastindex and match.lastindex >= 2:
                            replacement = match.group(match.lastindex).strip()
                            if replacement:
                                modifications["violence_replacement"] = replacement
                    elif pattern_type == "reduce_profanity":
                        modifications["reduce_profanity"] = True
                    elif pattern_type == "reduce_gore":
                        modifications["reduce_gore"] = True
                    elif pattern_type == "reduce_sexual":
                        modifications["reduce_sexual"] = True
                    elif pattern_type == "reduce_drugs":
                        modifications["reduce_drugs"] = True

        replacement = modifications["violence_replacement"]
        if replacement and isinstance(replacement, str):
            verbal_sim = self._get_max_similarity(
                replacement, self.context_examples["replace_violence_verbal"]
            )
            mild_sim = self._get_max_similarity(
                replacement, self.context_examples["replace_violence_mild"]
            )

            if verbal_sim > 0.5:
                modifications["violence_replacement_type"] = "verbal"
            elif mild_sim > 0.5:
                modifications["violence_replacement_type"] = "mild"
            else:
                modifications["violence_replacement_type"] = "mild"

        return modifications

    def _get_max_similarity(self, text: str, examples: List[str]) -> float:
        """Calculate maximum semantic similarity between text and examples."""
        text_emb = self.embedder.encode([text], convert_to_numpy=True)[0]
        example_embs = self.embedder.encode(examples, convert_to_numpy=True)
        similarities = util.cos_sim(text_emb, example_embs)[0]
        return float(similarities.max())

    def apply_modifications(
        self, original_text: str, modifications: Dict[str, Any]
    ) -> Tuple[str, List[str]]:
        """Apply modifications to script text and return modified text + changes description."""
        scenes = parse_script_to_scenes(original_text)
        changes_description = []

        if modifications["remove_scenes"]:
            scenes_to_remove = set(modifications["remove_scenes"])
            original_count = len(scenes)
            scenes = [s for s in scenes if s["scene_id"] not in scenes_to_remove]
            removed_count = original_count - len(scenes)

            if removed_count > 0:
                changes_description.append(
                    f"Removed {removed_count} scene(s): {sorted(list(scenes_to_remove))}"
                )

            for idx, scene in enumerate(scenes):
                scene["scene_id"] = idx

        modified_scenes = []
        for scene in scenes:
            scene_text = scene["text"]

            if modifications["reduce_violence"]:
                replacement_type = modifications.get(
                    "violence_replacement_type", "mild"
                )
                scene_text, _ = self._reduce_violence_in_text(
                    scene_text, replacement_type
                )

            if modifications["reduce_profanity"]:
                scene_text, _ = self._reduce_profanity_in_text(scene_text)

            if modifications["reduce_gore"]:
                scene_text, _ = self._reduce_gore_in_text(scene_text)

            if modifications["reduce_sexual"]:
                scene_text, _ = self._reduce_sexual_in_text(scene_text)

            if modifications["reduce_drugs"]:
                scene_text, _ = self._reduce_drugs_in_text(scene_text)

            scene["text"] = scene_text
            modified_scenes.append(scene)

        if modifications["reduce_violence"]:
            changes_description.append("Reduced violence intensity across all scenes")
        if modifications["reduce_profanity"]:
            changes_description.append("Removed profanity throughout the script")
        if modifications["reduce_gore"]:
            changes_description.append("Reduced graphic gore and blood descriptions")
        if modifications["reduce_sexual"]:
            changes_description.append("Reduced sexual content and nudity")
        if modifications["reduce_drugs"]:
            changes_description.append("Reduced drug and alcohol references")

        modified_text = "\n\n".join([s["text"] for s in modified_scenes])
        return modified_text, changes_description

    def _reduce_violence_in_text(
        self, text: str, replacement_type: str = "mild"
    ) -> Tuple[str, bool]:
        """Reduce violence in text by replacing violent words with milder alternatives."""
        modified = False

        violence_replacements = {
            "kill": "confront",
            "shoot": "point at",
            "stab": "threaten",
            "murder": "argue with",
            "attack": "approach",
            "beating": "pushing",
            "fight": "argue" if replacement_type == "verbal" else "scuffle",
            "–∞–≤—Ç–æ–º–∞—Ç": "—É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ",
            "–≤–∏–Ω—Ç–æ–≤–∫–∞": "–∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç",
            "–ø–∏—Å—Ç–æ–ª–µ—Ç": "–ø—Ä–µ–¥–º–µ—Ç",
            "–æ—Ä—É–∂–∏–µ": "–ø—Ä–µ–¥–º–µ—Ç",
            "gun": "device",
            "rifle": "tool",
            "weapon": "item",
            "—É–±–∏—Ç—å": "–ø—Ä–æ—Ç–∏–≤–æ—Å—Ç–æ—è—Ç—å",
            "—É–±–∏–π—Å—Ç–≤–æ": "–∫–æ–Ω—Ñ–ª–∏–∫—Ç",
            "—Å—Ç—Ä–µ–ª—è—Ç—å": "–Ω–∞–ø—Ä–∞–≤–∏—Ç—å –Ω–∞",
            "–∑–∞—Ä–µ–∑–∞—Ç—å": "—É–≥—Ä–æ–∂–∞—Ç—å",
            "–∞—Ç–∞–∫–æ–≤–∞—Ç—å": "–ø—Ä–∏–±–ª–∏–∑–∏—Ç—å—Å—è",
            "–∏–∑–±–∏–µ–Ω–∏–µ": "—Ç–æ–ª–∫–∞–Ω–∏–µ",
            "–¥—Ä–∞–∫–∞": "—Å–ø–æ—Ä" if replacement_type == "verbal" else "–ø–æ—Ç–∞—Å–æ–≤–∫–∞",
            "–±—å–µ—Ç": "—Ç–æ–ª–∫–∞–µ—Ç",
            "—É–¥–∞—Ä–∏–ª": "–ø–æ–¥—Ç–æ–ª–∫–Ω—É–ª",
            "–ª–æ–º–∞–µ—Ç": "—Å–∫—Ä—É—á–∏–≤–∞–µ—Ç",
            "broke": "twisted",
            "smashed": "pushed",
            "crushed": "squeezed",
        }

        for violent_word, replacement in violence_replacements.items():
            pattern = r"\b" + re.escape(violent_word) + r"\w*"
            if re.search(pattern, text, re.I):
                text = re.sub(pattern, replacement, text, flags=re.I)
                modified = True

        return text, modified

    def _reduce_profanity_in_text(self, text: str) -> Tuple[str, bool]:
        """Remove profanity from text."""
        modified = False

        profanity_patterns = [
            (r"\bfuck\w*\b", "darn", re.I),
            (r"\bshit\b", "crap", re.I),
            (r"\bmotherfucker\b", "jerk", re.I),
            (r"\bbitch\b", "witch", re.I),
            (r"\basshole\b", "idiot", re.I),
            (r"\b–±–ª—è–¥—å\b", "—á–µ—Ä—Ç", re.I),
            (r"\b–±–ª—è\b", "–±–ª–∏–Ω", re.I),
            (r"\b—Å—É–∫–∞\b", "–∑–∞—Ä–∞–∑–∞", re.I),
            (r"\b—Ö—É–π\w*\b", "—á–µ—Ä—Ç", re.I),
            (r"\b–ø–∏–∑–¥\w*\b", "—á–µ—Ä—Ç", re.I),
            (r"\b–µ–±–∞—Ç—å\b", "—á–µ—Ä—Ç", re.I),
            (r"\b–µ–±–∞–ª\w*\b", "—á–µ—Ä—Ç", re.I),
            (r"\b–¥–µ—Ä—å–º\w*\b", "–µ—Ä—É–Ω–¥–∞", re.I),
            (r"\b–≥–æ–≤–Ω\w*\b", "–µ—Ä—É–Ω–¥–∞", re.I),
        ]

        for pattern, replacement, flags in profanity_patterns:
            if re.search(pattern, text, flags):
                text = re.sub(pattern, replacement, text, flags=flags)
                modified = True

        return text, modified

    def _reduce_gore_in_text(self, text: str) -> Tuple[str, bool]:
        """Reduce gore descriptions in text."""
        modified = False

        gore_replacements = {
            "blood": "mark",
            "bloody": "marked",
            "bleeding": "injured",
            "wound": "injury",
            "guts": "injury",
            "dismember": "injured",
            "gore": "impact",
            "mutilate": "harm",
            "–∫—Ä–æ–≤—å": "—Å–ª–µ–¥",
            "–∫—Ä–æ–≤–∞–≤—ã–π": "–ø–æ–º–µ—á–µ–Ω–Ω—ã–π",
            "–∫—Ä–æ–≤–æ—Ç–æ—á": "—Ä–∞–Ω–µ–Ω",
            "—Ä–∞–Ω–∞": "–ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–µ",
            "–∫–∏—à–∫–∏": "–ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–µ",
            "—É–≤–µ—á—å": "–ø–æ–≤—Ä–µ–∂–¥",
            "–∏–∑—É—Ä–æ–¥–æ–≤–∞–Ω": "–ø–æ–≤—Ä–µ–∂–¥–µ–Ω",
            "—Ä–∞—Å—á–ª–µ–Ω–µ–Ω": "–ø–æ–≤—Ä–µ–∂–¥–µ–Ω",
            "–±—Ä—ã–∑–≥–∞": "–ø–æ–ª–µ—Ç",
            "—Ç–µ–∫–ª–∞": "–ø–æ—è–≤–∏–ª–∞—Å—å",
            "–ø—Ä–æ–ª–∏–ª–∞—Å—å": "–æ–±—Ä–∞–∑–æ–≤–∞–ª–∞—Å—å",
        }

        for gore_word, replacement in gore_replacements.items():
            pattern = r"\b" + re.escape(gore_word) + r"\w*"
            if re.search(pattern, text, re.I):
                text = re.sub(pattern, replacement, text, flags=re.I)
                modified = True

        return text, modified

    def _reduce_sexual_in_text(self, text: str) -> Tuple[str, bool]:
        """Reduce sexual content in text."""
        modified = False

        sexual_patterns = [
            (r"\brape\b", "assault", re.I),
            (r"\bsex scene\b", "romantic scene", re.I),
            (r"\bnaked\b", "undressed", re.I),
            (r"\bnude\b", "unclothed", re.I),
            (r"\b–∏–∑–Ω–∞—Å–∏–ª–æ–≤\w*\b", "–Ω–∞–ø–∞–¥", re.I),
            (r"\b—Å–µ–∫—Å—É–∞–ª—å–Ω\w*\b", "—Ä–æ–º–∞–Ω—Ç–∏—á–µ—Å–∫", re.I),
            (r"\b–≥–æ–ª—ã–π\b", "—Ä–∞–∑–¥–µ—Ç—ã–π", re.I),
            (r"\b–≥–æ–ª–∞—è\b", "—Ä–∞–∑–¥–µ—Ç–∞—è", re.I),
        ]

        for pattern, replacement, flags in sexual_patterns:
            if re.search(pattern, text, flags):
                text = re.sub(pattern, replacement, text, flags=flags)
                modified = True

        return text, modified

    def _reduce_drugs_in_text(self, text: str) -> Tuple[str, bool]:
        """Reduce drug references in text."""
        modified = False

        drug_patterns = [
            (r"\bheroin\b", "substance", re.I),
            (r"\bcocaine\b", "substance", re.I),
            (r"\bmarijuana\b", "substance", re.I),
            (r"\b–≥–µ—Ä–æ–∏–Ω\b", "–≤–µ—â–µ—Å—Ç–≤–æ", re.I),
            (r"\b–∫–æ–∫–∞–∏–Ω\b", "–≤–µ—â–µ—Å—Ç–≤–æ", re.I),
            (r"\b–º–∞—Ä–∏—Ö—É–∞–Ω\w*\b", "–≤–µ—â–µ—Å—Ç–≤–æ", re.I),
        ]

        for pattern, replacement, flags in drug_patterns:
            if re.search(pattern, text, flags):
                text = re.sub(pattern, replacement, text, flags=flags)
                modified = True

        return text, modified

    def simulate_what_if(self, original_text: str, user_request: str) -> Dict[str, Any]:
        """Simulate what-if scenario and return rating comparison."""
        logger.info(f"Processing what-if request: {user_request}")

        original_result = self._analyze_script(original_text)

        modifications = self.analyze_modification_request(user_request)
        modified_text, changes = self.apply_modifications(original_text, modifications)

        modified_result = self._analyze_script(modified_text)

        explanation = self._generate_explanation(
            original_result, modified_result, changes, modifications
        )

        return {
            "original_rating": original_result["rating"],
            "modified_rating": modified_result["rating"],
            "original_scores": original_result["scores"],
            "modified_scores": modified_result["scores"],
            "changes_applied": changes,
            "explanation": explanation,
            "rating_changed": original_result["rating"] != modified_result["rating"],
        }

    def _analyze_script(self, text: str) -> Dict[str, Any]:
        """Analyze script and return rating with scores."""
        scenes = parse_script_to_scenes(text)

        features = []
        for scene in scenes:
            feat = extract_scene_features(scene["text"])
            features.append(feat)

        scores = [normalize_and_contextualize_scores(f) for f in features]

        score_keys = [
            "violence",
            "gore",
            "sex_act",
            "nudity",
            "profanity",
            "drugs",
            "child_risk",
        ]
        agg = {}

        for k in score_keys:
            values = [s[k] for s in scores]
            max_val = float(np.max(values))
            p95_val = float(np.percentile(values, 95))
            p90_val = float(np.percentile(values, 90))

            if k in ["violence", "gore"]:
                agg[k] = max_val * 0.7 + p95_val * 0.3
            elif k in ["sex_act", "nudity", "child_risk"]:
                agg[k] = max_val * 0.85 + p90_val * 0.15
            else:
                agg[k] = float(np.percentile(values, 90))

        all_excerpts: Dict[str, List[Any]] = {
            "violence": [],
            "gore": [],
            "sex": [],
            "nudity": [],
            "profanity": [],
            "drugs": [],
        }
        for s in scores:
            for key in all_excerpts.keys():
                all_excerpts[key].extend(s["excerpts"][key])

        limited_excerpts = {k: v[:5] for k, v in all_excerpts.items()}
        agg["excerpts"] = cast(Any, limited_excerpts)

        rating_info = map_scores_to_rating(agg)

        return {
            "rating": rating_info["rating"],
            "reasons": rating_info["reasons"],
            "scores": {k: round(agg[k], 3) for k in score_keys},
            "total_scenes": len(scenes),
        }

    def _generate_explanation(
        self,
        original: Dict[str, Any],
        modified: Dict[str, Any],
        changes: List[str],
        modifications: Dict[str, Any],
    ) -> str:
        """Generate human-readable explanation of rating change."""
        if original["rating"] == modified["rating"]:
            explanation = (
                f"–†–µ–π—Ç–∏–Ω–≥ –æ—Å—Ç–∞–ª—Å—è –ø—Ä–µ–∂–Ω–∏–º: {original['rating']}. "
                f"–í–Ω–µ—Å–µ–Ω–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è ({', '.join(changes)}) "
                f"–Ω–µ –±—ã–ª–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–º–∏ –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤–æ–∑—Ä–∞—Å—Ç–Ω–æ–≥–æ —Ä–µ–π—Ç–∏–Ω–≥–∞."
            )

            score_changes = []
            for key in ["violence", "gore", "sex_act", "nudity", "profanity", "drugs"]:
                orig_score = original["scores"].get(key, 0)
                mod_score = modified["scores"].get(key, 0)
                diff = mod_score - orig_score

                if abs(diff) > 0.05:
                    direction = "—É–≤–µ–ª–∏—á–∏–ª—Å—è" if diff > 0 else "—Å–Ω–∏–∑–∏–ª—Å—è"
                    score_changes.append(f"{key}: {direction} –Ω–∞ {abs(diff):.2f}")

            if score_changes:
                explanation += f" –ò–∑–º–µ–Ω–µ–Ω–∏—è –≤ –æ—Ü–µ–Ω–∫–∞—Ö: {', '.join(score_changes)}."
        else:
            direction = (
                "–ø–æ–≤—ã—Å–∏–ª—Å—è" if modified["rating"] > original["rating"] else "–ø–æ–Ω–∏–∑–∏–ª—Å—è"
            )
            explanation = (
                f"–†–µ–π—Ç–∏–Ω–≥ {direction}: –±—ã–ª–æ {original['rating']}, —Å—Ç–∞–ª–æ {modified['rating']}. "
                f"–ò–∑–º–µ–Ω–µ–Ω–∏—è: {', '.join(changes)}. "
            )

            key_changes = []
            for key in ["violence", "gore", "sex_act", "nudity", "profanity", "drugs"]:
                orig_score = original["scores"].get(key, 0)
                mod_score = modified["scores"].get(key, 0)
                diff = mod_score - orig_score

                if abs(diff) > 0.1:
                    direction = "—É–≤–µ–ª–∏—á–µ–Ω" if diff > 0 else "—Å–Ω–∏–∂–µ–Ω"
                    key_changes.append(
                        f"{key} {direction} —Å {orig_score:.2f} –¥–æ {mod_score:.2f}"
                    )

            if key_changes:
                explanation += f"–ö–ª—é—á–µ–≤—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è: {', '.join(key_changes)}."

        return explanation

    def generate_smart_suggestions(
        self,
        script_text: str,
        current_scores: Dict[str, float] | None = None,
        language: str = "ru",
        max_suggestions: int = 8,
    ) -> Dict[str, Any]:
        """Generate smart, personalized suggestions based on script analysis."""
        logger.info("Generating smart suggestions for script")

        # Analyze script if scores not provided
        if current_scores is None:
            analysis = self._analyze_script(script_text)
            current_scores = analysis["scores"]
            current_rating = analysis["rating"]
            total_scenes = analysis["total_scenes"]
        else:
            # Quick analysis for rating
            analysis = self._analyze_script(script_text)
            current_rating = analysis["rating"]
            total_scenes = analysis["total_scenes"]

        # Parse scenes for detailed analysis
        scenes = parse_script_to_scenes(script_text)

        suggestions = []

        # Define thresholds and icons
        category_config = {
            "violence": {
                "threshold": 0.3,
                "icon": "üí¨",
                "ru": "–Ω–∞—Å–∏–ª–∏–µ",
                "en": "violence",
            },
            "gore": {"threshold": 0.25, "icon": "ü©π", "ru": "–∫—Ä–æ–≤—å", "en": "gore"},
            "profanity": {
                "threshold": 0.3,
                "icon": "ü§ê",
                "ru": "–º–∞—Ç",
                "en": "profanity",
            },
            "sex_act": {
                "threshold": 0.2,
                "icon": "üîû",
                "ru": "—Å–µ–∫—Å",
                "en": "sexual content",
            },
            "nudity": {"threshold": 0.2, "icon": "üëó", "ru": "–Ω–∞–≥–æ—Ç–∞", "en": "nudity"},
            "drugs": {"threshold": 0.2, "icon": "üíä", "ru": "–Ω–∞—Ä–∫–æ—Ç–∏–∫–∏", "en": "drugs"},
        }

        # Analyze each category
        for category, config in category_config.items():
            score = current_scores.get(category, 0)

            if score > config["threshold"]:
                # Find problematic scenes
                affected_scenes = []
                for scene in scenes:
                    features = extract_scene_features(scene["text"])
                    normalized = normalize_and_contextualize_scores(features)
                    if normalized.get(category, 0) > 0.5:
                        affected_scenes.append(scene["scene_id"])

                # Calculate priority (higher score = higher priority)
                priority = min(10, int(score * 10) + 2)
                confidence = min(1.0, score * 1.2)

                # Generate suggestion text based on language
                if language == "ru":
                    category_name = config["ru"]
                    if len(affected_scenes) > 0:
                        if len(affected_scenes) == 1:
                            suggestion_text = (
                                f"—É–±—Ä–∞—Ç—å {category_name} –≤ —Å—Ü–µ–Ω–µ {affected_scenes[0]}"
                            )
                        elif len(affected_scenes) <= 3:
                            scenes_str = ", ".join(map(str, affected_scenes[:3]))
                            suggestion_text = (
                                f"—É–±—Ä–∞—Ç—å {category_name} –≤ —Å—Ü–µ–Ω–∞—Ö {scenes_str}"
                            )
                        else:
                            suggestion_text = f"—Å–º—è–≥—á–∏—Ç—å {category_name} ({len(affected_scenes)} —Å—Ü–µ–Ω)"
                    else:
                        suggestion_text = f"—É–±—Ä–∞—Ç—å {category_name}"

                    reasoning = f"–£—Ä–æ–≤–µ–Ω—å {category_name}: {int(score * 100)}% - –≤—ã—à–µ –Ω–æ—Ä–º—ã –¥–ª—è –±–æ–ª–µ–µ –Ω–∏–∑–∫–æ–≥–æ —Ä–µ–π—Ç–∏–Ω–≥–∞"
                else:
                    category_name = config["en"]
                    if len(affected_scenes) > 0:
                        if len(affected_scenes) == 1:
                            suggestion_text = (
                                f"remove {category_name} in scene {affected_scenes[0]}"
                            )
                        elif len(affected_scenes) <= 3:
                            scenes_str = ", ".join(map(str, affected_scenes[:3]))
                            suggestion_text = (
                                f"remove {category_name} in scenes {scenes_str}"
                            )
                        else:
                            suggestion_text = f"reduce {category_name} ({len(affected_scenes)} scenes)"
                    else:
                        suggestion_text = f"remove {category_name}"

                    reasoning = f"{category_name.capitalize()} level: {int(score * 100)}% - above threshold for lower rating"

                suggestions.append(
                    {
                        "text": suggestion_text,
                        "category": category,
                        "icon": config["icon"],
                        "priority": priority,
                        "confidence": confidence,
                        "affected_scenes": affected_scenes[:5],  # Limit to 5 scenes
                        "reasoning": reasoning,
                    }
                )

        # Sort by priority (descending)
        suggestions.sort(key=lambda x: (-x["priority"], -x["confidence"]))

        # Limit to max_suggestions
        suggestions = suggestions[:max_suggestions]

        # Generate summary
        if language == "ru":
            high_scores = [k for k, v in current_scores.items() if v > 0.5]
            if high_scores:
                summary = f"–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –≤—ã—Å–æ–∫–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏: {', '.join(high_scores)}. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —Å–º—è–≥—á–∏—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –±–æ–ª–µ–µ –Ω–∏–∑–∫–æ–≥–æ —Ä–µ–π—Ç–∏–Ω–≥–∞."
            else:
                summary = f"–°—Ü–µ–Ω–∞—Ä–∏–π –∏–º–µ–µ—Ç —Ä–µ–π—Ç–∏–Ω–≥ {current_rating}. –ü—Ä–µ–¥–ª–æ–∂–µ–Ω—ã —É–ª—É—á—à–µ–Ω–∏—è –¥–ª—è —Å–Ω–∏–∂–µ–Ω–∏—è –≤–æ–∑—Ä–∞—Å—Ç–Ω—ã—Ö –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π."
        else:
            high_scores = [k for k, v in current_scores.items() if v > 0.5]
            if high_scores:
                summary = f"High levels detected: {', '.join(high_scores)}. Consider reducing content for lower rating."
            else:
                summary = f"Script rated {current_rating}. Suggestions provided to reduce age restrictions."

        return {
            "suggestions": suggestions,
            "analysis_summary": summary,
            "current_rating": current_rating,
            "total_scenes": total_scenes,
        }


_analyzer: WhatIfAnalyzer | None = None


def get_what_if_analyzer() -> WhatIfAnalyzer:
    global _analyzer
    if _analyzer is None:
        _analyzer = WhatIfAnalyzer()
    return _analyzer
